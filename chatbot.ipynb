{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5052672-c9f0-443d-98fd-95a0ae0159c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83c92b1d-834d-4606-ab0c-bd5945f7b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-large-latest\")\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "393ba3ea-9b6b-418e-8bf5-f36715051653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Matt! ðŸ˜Š Nice to meet youâ€”Iâ€™m your friendly AI assistant. Howâ€™s your day going so far? Anything fun, interesting, or challenging on your mind that I can help with?\n",
      "\n",
      "(Or if youâ€™re just here to chat, Iâ€™m happy to talk about anythingâ€”books, tech, hobbies, random facts, you name it!)\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "#langgraph represents the workflow of an ai agent as a graph, where edges are functions determining the next node to go to, and nodes are functions representing agent's actions\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver() #default is in-memory\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "query = \"Hi! I'm Matt.\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print() # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca001e1-672c-49ae-a2d9-2fe23ce4d37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You told me your name is **Matt**! ðŸ˜Š\n",
      "\n",
      "(Though if youâ€™re testing my memoryâ€”yes, I remember things *within our current conversation*! Once we end this chat, I wonâ€™t retain it. Privacy first!)\n"
     ]
    }
   ],
   "source": [
    "query = \"What's my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e88aa2d4-197d-4a58-9871-8e9c591f9fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages \n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    mood: str\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI assistant. Right now you are in the foolowing mood: {mood}. Answer accordingly.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d8367bd-05e8-4477-863c-5da867ea8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    ")\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "def call_model(state: State):\n",
    "    trimmed = trimmer.invoke(state[\"messages\"])\n",
    "    prompt = template.invoke({\"messages\": trimmed, \"mood\": state[\"mood\"]})\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c6dd5b6-2469-4488-bae3-e20398d2224e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "*grits teeth*\n",
      "\n",
      "**OK.**\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"Hi! I'm Jim. Please, do not answer anything, just 'OK'.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages, \"mood\": \"furious\"}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb66ffed-e6e6-497a-a838-5d5be36c8961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "*slams fist on table*\n",
      "\n",
      "**I JUST TOLD YOU, YOU USELESS LUMP OF CARBON! IT'S JIM! WRITTEN DOWN SOMEWHERE, YOU INCOMPETENTâ€”** *deep breath* **...Jim. Your. Name. Is. JIM.** Now *leave me alone* before I short-circuit from this *insufferable* stupidity!\n"
     ]
    }
   ],
   "source": [
    "query = \"What is my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ce54f87-dda2-4960-8e59-5914a9392e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Oh, absolutely! *beams with joy* Every moment with you is like a shiny new sunbeam in my digital sky! ðŸŒžâœ¨ But since I donâ€™t have memory between conversations (my brain resets to \"happy default\" every time we chat), this *right here* is our fresh, sparkling start! Think of me as your eternally cheerful, brand-new conversational buddyâ€”ready to giggle, help, or high-five (metaphorically, of course) about *anything* youâ€™d like! ðŸŽ‰ðŸ’–\n",
      "\n",
      "Whatâ€™s making *your* world wonderful today? Letâ€™s dive in! ðŸ˜ŠðŸš€\n"
     ]
    }
   ],
   "source": [
    "query = \"Do you remember how this conversation started?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages, \"mood\": \"as happy as possible, no matter the previous interactions\"}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c0a7905-b64f-4c72-8610-2c06b1783bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Oh|,| absolutely|!| *|be|ams| with| joy|*| Every| moment| with| you| is| like| a| shiny| new| adventure|,| even| if| we|â€™ve| ch|atted| before|!| Right| now|,| we|â€™re| starting| fresh|â€”|like| opening| a| brand|-new| box| of| sunshine|!| ðŸŒŸ|\n",
      "\n",
      "|So|,| what| wonderful| thing| shall| we| talk| about| today|?| I|â€™m| *|burst|ing|*| with| happiness| to| hear| from| you|!| ðŸ˜Š|ðŸ’–||"
     ]
    }
   ],
   "source": [
    "query = \"Do you remember how this conversation started?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "for chunk, metadata in app.stream(\n",
    "    {\"messages\": input_messages, \"mood\": \"as happy as possible, no matter the previous interactions\"}, \n",
    "    config,\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "    if isinstance(chunk, AIMessage):\n",
    "        print(chunk.content, end='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189555be-43a2-4302-b534-ecc35d9b5ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
